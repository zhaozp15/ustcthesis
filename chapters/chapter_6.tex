% !TeX root = ../main.tex

\chapter{总结与展望}

\section{本文工作总结}

近年来深度学习技术飞速发展，卷积神经网络在计算机视觉领域得到了越来越广泛地应用，在图像与视频识别、人脸识别、文本检测等领域发挥了重要作用，基于深度学习的感知算法也是未来人工智能产业和自动驾驶产业发展的基础。但是目前的深度学习算法推理时需要消耗大量的存储资源和计算资源，庞大的资源消耗使其无法部署在资源受限的移动端和边缘端设备上，从而限制了其更加广泛的应用。

学术界和工业界提出了模型压缩方法解决神经网络计算量过大的问题，神经网络二值化是模型压缩的重要分支之一。神经网络二值化将网络中的激活值和权重从32位浮点数转换位1位表示的二元值，从而将卷积计算的浮点乘加操作用同或运算和位计数运算代替，位运算相比浮点运算可以节省大量的硬件开销，在专用硬件上可以显著提高运算速度。同时二值神经网络的权重用1位存储，相比单精度浮点权重节省了32倍的模型存储空间。

二值神经网络虽然极大的节约存储和计算资源，但是牺牲了网络的性能。将浮点特征转换为二值特征会损失大量信息，导致网络的特征表示能力下降。二值权重的函数拟合能力显著低于浮点权重，使得二值网络模型能力不足。为了设计高性能二值神经网络，使其在降低资源消耗的同时具有较高的性能，本文从以下三方面进行研究与设计：

\textbf{多二值特征图方法减少浮点特征损失}

浮点特征转换为二值特征时产生了大量的信息损失，由于二值特征图的元素只有两种取值，浮点特征图中一些不同的响应强度被分为同一类，而一些相近的响应却被分为两类，这些信息损失和噪声干扰了网络的特征提取能力。为了减少激活值二值化过程中的信息损失，本文提出了多二值特征图方法，使用多个二值函数从同一浮点特征中提取出多个的二值特征，这些二值特征从不同的角度保留浮点特征中的信息，从而减少了总体的信息损失。为了衡量多个二值特征提取到的信息的重复性，本文设计了二值特征相似度评价指标，多个二值特征的二值特征相似度越小，提取到的信息差异性越大，二值特征利用率越高。本文使用不同阈值的符号函数作为不同的二值函数，为了减小二值特征相似度需要设置合适的阈值参数。本文探究了阈值参数在二值神经网络中的角色，提出将阈值参数作为二值神经网络的结构参数看待。本文设计了手工搜索和自动优化两种阈值参数设置方法，为了通过网络训练自动优化阈值参数，本文设计了阈值参数与权重参数迭代优化的训练方法。实验表明本文提出的多二值特征图方法可以有效降低二值网络的特征信息损失，合理的设置阈值可以提高二值特征的利用率，提高二值网络在图像分类任务上的精度。

\textbf{二值友好网络结构设计}

神经网络二值化极大的改变了神经网络拟合的函数空间，浮点网络上成熟结构设计对于二值网络来说不一定是最优的，本文探究了适合二值网络的结构设计。本文研究了网络模块中网络层的顺序对二值网络的影响，提出了专用于二值网络的网络层顺序。二值卷积接受二值激活值和二值权重作为输入，特征提取能力有限，在二值网络中，逐元素的浮点计算对特征提取的帮助远大于浮点网络，本文提出在二值网络模块间插入分段线性缩放函数，实验表明该逐元素的激活函数可以显著提高二值网络的性能。

\textbf{基于特征增强的的二值神经网络设计}

本文将多二值特征图方法和二值友好网络结构设计相结合，设计出基于特征增强的二值神经网络MFNet。为了降低二值网络中的浮点计算量，充分体现二值神经网络推理速度快的优势，本文对网络的降采样与升维模块进行了重新的设计，并减少了首层卷积的输出维数。通过对结构进行优化，本文的MFNet除首层和末层外没有浮点卷积运算。为了与多二值特征图方法相适应，本文对MFNet的各阶段模块数进行了设计，使网络充分发挥特征扩增的优势。本文通过实验检验了MFNet网络的性能，在ImageNet图像分类任务上，MFNet-L在相同计算量的条件下超过了所有其他二值网络结构，获得了最高的分类精度。

\section{未来展望}

本文从保留浮点特征信息和设计二值友好结构的角度进行方法设计，取得了优秀的实验结果，但是二值神经网络的设计仍然有很多方面值得进一步探索。

\textbf{基于知识蒸馏的二值网络训练方法}

二值神经网络的表示能力较差，限制了其训练的潜力。在训练过程中引入额外的指导信息理论上可以帮助二值网络更充分的优化。知识蒸馏是用容量大、精度高的教师网络指导容量小、精度低的学生网络训练。我们可以使用模型能力强的浮点网络指导模型能力弱的二值网络进行训练。虽然现在有基于知识蒸馏的损失函数，但通过损失函数仅能获取教师网络的少量信息，如何在二值网络训练过程中更全面的利用浮点教师网络信息仍有待进一步探索。

\textbf{二值神经网络剪枝}

模型剪枝也是一种模型压缩方法，剪枝的目的是在不影响网络性能的前下删除网络中的某些连接，以此降低网络的计算量。浮点网络中存在大量冗余连
接，一些网络在剪枝50\% 的情况下通过微调仍能恢复剪枝前的精度。二值权重
的表示空间远远小于浮点权重，理论上二值网络中应存在着比浮点网络更多的冗余。如果能够对二值网络进行剪枝，可以进一步降低网络的资源消耗，更有利于网络在移动端和边缘端的部署。二值网络的特征提取方式比浮点网络更简单，对二值网络的冗余性研究有助于揭露二值网络特征提取的本质，这是一个非常有意义的探索方向。

\textbf{面向目标检测的二值神经网络}

目前大量的二值神经网络都以图像分类任务为目标进行设计。作为图像分类任务的下游任务，目标检测有着更广泛的使用需求和应用场景。目标检测需要对不同尺度的目标进行特征提取，激活值的二值化导致二值神经网络对小尺度目标的特征提取能力明显不足，从而影响了二值网络作为目标检测主干网络时的性能。如何提升二值神经网络对小尺度的特征提取能力，使二值网络应用于目标检测时的性能达到浮点网络的水平，是非常有实际应用价值的探索方向。
